{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6761311",
   "metadata": {},
   "source": [
    "# Simulated Annealing and GSA for Feature Selection\n",
    "## Simulated Annealing Algorithm) For Feature Selection on Churn Prediction\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea8c4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the directory of the current script or notebook\n",
    "script_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Construct the full path to the 'src' directory\n",
    "src_dir = os.path.join(script_dir, '..', 'src')\n",
    "\n",
    "# Append the 'src' directory to sys.path\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Construct the full path to the 'data' directory\n",
    "data_dir = os.path.join(script_dir, '..', 'data')\n",
    "\n",
    "# Now, you can import the modules and access the data\n",
    "from main import simulated_annealing\n",
    "from GSA_implementation import GSA\n",
    "#from benchmarks import F1 \n",
    "from gsa_sa_iterative import gsa_sa_iterative\n",
    "from generate_neighbor import generate_neighbor\n",
    "# from utils import fitness_function, train_model\n",
    "from utils3 import train_model\n",
    "\n",
    "\n",
    "# Load your data (example)\n",
    "import pandas as pd\n",
    "\n",
    "# #dataset1\n",
    "#df = pd.read_csv(os.path.join(data_dir, 'churn2.csv'))\n",
    "\n",
    "# dataset2\n",
    "df = pd.read_csv(os.path.join(data_dir, 'ChurnNormalize.csv'))\n",
    "\n",
    "#dataset3\n",
    "#df = pd.read_csv(os.path.join(data_dir, 'cell2cell.csv'))\n",
    "\n",
    "#dataset4\n",
    "# df = pd.read_csv(os.path.join(data_dir, 'telecom_churn.csv'))\n",
    "\n",
    "#dataset5\n",
    "#df = pd.read_csv(os.path.join(data_dir, 'cleaned_dataset5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f994fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append(r'C:\\Users\\fakep\\Documents\\S3 ITS\\Machine Learning with Python\\Simulated-Annealing-Feature-Selection-main\\src')\n",
    "sys.path.append(r'C:\\Users\\hendr\\Documents\\S3 ITS\\Machine Learning with Python\\MachineLearning\\Simulated-Annealing-Feature-Selection-main\\src')\n",
    "\n",
    "from main import simulated_annealing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068b4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime as dt\n",
    "from utils import train_model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from GSA_implementation import GSA\n",
    "from benchmarks import F1\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "#classifiers_name = \"KNN\"\n",
    "\n",
    "#classifiers_name = {\n",
    "#      \"Random Forest\": RandomForestClassifier(),\n",
    "#      \"SVM\": SVC(),\n",
    "#      \"Decision Tree\": DecisionTreeClassifier(),\n",
    "#      \"Logistic Regression\": LogisticRegression(),\n",
    "#      \"Naive Bayes\": GaussianNB(),\n",
    "#      \"KNN\": KNeighborsClassifier(),\n",
    "#      \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81058f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#df = pd.read_csv(r'C:\\Users\\fakep\\Documents\\S3 ITS\\Machine Learning with Python\\Simulated-Annealing-Feature-Selection-main\\data\\churn2.csv')\n",
    "#df = pd.read_csv(r'C:\\Users\\hendr\\Documents\\S3 ITS\\Machine Learning with Python\\MachineLearning\\Simulated-Annealing-Feature-Selection-main\\data\\churn2.csv')\n",
    "# Drop the first column\n",
    "#df = df.iloc[:, 1:]\n",
    "\n",
    "#dataset1\n",
    "# Assuming the target variable is named 'target' and all others are features\n",
    "# X_train = df.drop(columns=['churn'])\n",
    "# X_train = df.iloc[:, 1:-1] \n",
    "# X_train = df.drop(columns=['Unnamed: 0', 'churn'])\n",
    "# y_train = df['churn']\n",
    "\n",
    "#dataset2\n",
    "X_train = df.drop(columns=['Churn'])\n",
    "y_train = df['Churn']\n",
    "\n",
    "#dataset3 & 4\n",
    "# X_train = df.drop(columns=['Churn'])\n",
    "# y_train = df['Churn']\n",
    "\n",
    "#dataset5\n",
    "#X = df.drop(columns=['churn'])\n",
    "#y = df['churn']\n",
    "\n",
    "#print(X_train.head())\n",
    "#print(y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccd98ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.003437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>0.217564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.012453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.211951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>0.017462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
       "0       1              0        0           1  0.013889             0   \n",
       "1       0              0        1           1  0.472222             1   \n",
       "2       0              0        1           1  0.027778             1   \n",
       "3       0              0        1           1  0.625000             0   \n",
       "4       1              0        1           1  0.027778             1   \n",
       "\n",
       "   MultipleLines  InternetService  OnlineSecurity  OnlineBackup  \\\n",
       "0              0                1               2             1   \n",
       "1              1                1               1             2   \n",
       "2              1                1               1             1   \n",
       "3              0                1               1             2   \n",
       "4              1                2               2             2   \n",
       "\n",
       "   DeviceProtection  TechSupport  StreamingTV  StreamingMovies  Contract  \\\n",
       "0                 2            2            2                2         2   \n",
       "1                 1            2            2                2         1   \n",
       "2                 2            2            2                2         2   \n",
       "3                 1            1            2                2         1   \n",
       "4                 2            2            2                2         2   \n",
       "\n",
       "   PaperlessBilling  PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "0                 1              3        0.115423      0.003437  \n",
       "1                 0              2        0.385075      0.217564  \n",
       "2                 1              2        0.354229      0.012453  \n",
       "3                 0              1        0.239303      0.211951  \n",
       "4                 1              3        0.521891      0.017462  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd8d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c8a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a6e5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Adaptive GSA-SA with KNN (Run 1)...\n",
      "Starting SA Iteration 1\n",
      "GSA is optimizing  \"<lambda>\"\n",
      "[iter 1] G=10.0000\n",
      "[iter 1] kbest=20\n",
      "['At iteration 1 the best fitness is 0.23751210526315789']\n",
      "[iter 2] G=9.3551\n",
      "[iter 2] kbest=20\n",
      "['At iteration 2 the best fitness is 0.2293415789473684']\n",
      "[iter 3] G=8.7517\n",
      "[iter 3] kbest=19\n",
      "['At iteration 3 the best fitness is 0.2293415789473684']\n",
      "['At iteration 4 the best fitness is 0.22457947368421052']\n",
      "['At iteration 5 the best fitness is 0.22207315789473683']\n",
      "['At iteration 6 the best fitness is 0.21956684210526312']\n",
      "['At iteration 7 the best fitness is 0.21956684210526312']\n",
      "['At iteration 8 the best fitness is 0.21752421052631576']\n",
      "['At iteration 9 the best fitness is 0.21752421052631576']\n",
      "['At iteration 10 the best fitness is 0.21560684210526312']\n",
      "['At iteration 11 the best fitness is 0.21560684210526312']\n",
      "['At iteration 12 the best fitness is 0.21560684210526312']\n",
      "['At iteration 13 the best fitness is 0.21560684210526312']\n",
      "['At iteration 14 the best fitness is 0.21560684210526312']\n",
      "['At iteration 15 the best fitness is 0.21560684210526312']\n",
      "['At iteration 16 the best fitness is 0.21560684210526312']\n",
      "['At iteration 17 the best fitness is 0.21560684210526312']\n",
      "['At iteration 18 the best fitness is 0.21560684210526312']\n",
      "['At iteration 19 the best fitness is 0.21554421052631575']\n",
      "['At iteration 20 the best fitness is 0.21554421052631575']\n",
      "['At iteration 21 the best fitness is 0.21554421052631575']\n",
      "['At iteration 22 the best fitness is 0.21554421052631575']\n",
      "['At iteration 23 the best fitness is 0.21356421052631575']\n",
      "['At iteration 24 the best fitness is 0.21356421052631575']\n",
      "['At iteration 25 the best fitness is 0.21356421052631575']\n",
      "['At iteration 26 the best fitness is 0.21356421052631575']\n",
      "['At iteration 27 the best fitness is 0.21356421052631575']\n",
      "['At iteration 28 the best fitness is 0.21356421052631575']\n",
      "['At iteration 29 the best fitness is 0.21356421052631575']\n",
      "['At iteration 30 the best fitness is 0.21356421052631575']\n",
      "['At iteration 31 the best fitness is 0.21356421052631575']\n",
      "['At iteration 32 the best fitness is 0.21356421052631575']\n",
      "['At iteration 33 the best fitness is 0.21356421052631575']\n",
      "['At iteration 34 the best fitness is 0.21356421052631575']\n",
      "['At iteration 35 the best fitness is 0.21356421052631575']\n",
      "['At iteration 36 the best fitness is 0.21356421052631575']\n",
      "['At iteration 37 the best fitness is 0.21356421052631575']\n",
      "['At iteration 38 the best fitness is 0.21356421052631575']\n",
      "['At iteration 39 the best fitness is 0.21356421052631575']\n",
      "['At iteration 40 the best fitness is 0.21356421052631575']\n",
      "['At iteration 41 the best fitness is 0.21356421052631575']\n",
      "['At iteration 42 the best fitness is 0.21356421052631575']\n",
      "['At iteration 43 the best fitness is 0.21356421052631575']\n",
      "['At iteration 44 the best fitness is 0.21356421052631575']\n",
      "['At iteration 45 the best fitness is 0.21356421052631575']\n",
      "['At iteration 46 the best fitness is 0.21356421052631575']\n",
      "['At iteration 47 the best fitness is 0.21356421052631575']\n",
      "['At iteration 48 the best fitness is 0.21356421052631575']\n",
      "['At iteration 49 the best fitness is 0.21356421052631575']\n",
      "['At iteration 50 the best fitness is 0.21356421052631575']\n",
      "['At iteration 51 the best fitness is 0.21356421052631575']\n",
      "['At iteration 52 the best fitness is 0.21356421052631575']\n",
      "['At iteration 53 the best fitness is 0.21356421052631575']\n",
      "['At iteration 54 the best fitness is 0.21356421052631575']\n",
      "['At iteration 55 the best fitness is 0.21356421052631575']\n",
      "['At iteration 56 the best fitness is 0.21356421052631575']\n",
      "['At iteration 57 the best fitness is 0.21356421052631575']\n",
      "['At iteration 58 the best fitness is 0.21356421052631575']\n",
      "['At iteration 59 the best fitness is 0.21356421052631575']\n",
      "['At iteration 60 the best fitness is 0.21356421052631575']\n",
      "['At iteration 61 the best fitness is 0.21356421052631575']\n",
      "['At iteration 62 the best fitness is 0.21356421052631575']\n",
      "['At iteration 63 the best fitness is 0.21356421052631575']\n",
      "['At iteration 64 the best fitness is 0.21356421052631575']\n",
      "['At iteration 65 the best fitness is 0.21356421052631575']\n",
      "['At iteration 66 the best fitness is 0.21356421052631575']\n",
      "['At iteration 67 the best fitness is 0.21356421052631575']\n",
      "['At iteration 68 the best fitness is 0.21356421052631575']\n",
      "['At iteration 69 the best fitness is 0.21356421052631575']\n",
      "['At iteration 70 the best fitness is 0.21356421052631575']\n",
      "['At iteration 71 the best fitness is 0.21356421052631575']\n",
      "['At iteration 72 the best fitness is 0.21356421052631575']\n",
      "['At iteration 73 the best fitness is 0.21356421052631575']\n",
      "[iter 74] G=1.0000\n",
      "[iter 74] kbest=5\n",
      "['At iteration 74 the best fitness is 0.21356421052631575']\n",
      "[iter 75] G=1.0000\n",
      "[iter 75] kbest=5\n",
      "['At iteration 75 the best fitness is 0.21356421052631575']\n",
      "Accepted new solution with fitness 0.21600789473684207\n",
      "Accepted new solution with fitness 0.21699789473684208\n",
      "Accepted new solution with fitness 0.21752421052631576\n",
      "Accepted new solution with fitness 0.22451684210526313\n",
      "Accepted new solution with fitness 0.22003052631578943\n",
      "Accepted new solution with fitness 0.22293789473684208\n",
      "Accepted new solution with fitness 0.22597052631578946\n",
      "Accepted new solution with fitness 0.22003052631578943\n",
      "Accepted new solution with fitness 0.22102052631578945\n",
      "Accepted new solution with fitness 0.21904052631578944\n",
      "Accepted new solution with fitness 0.22993052631578945\n",
      "Accepted new solution with fitness 0.22702315789473684\n",
      "Accepted new solution with fitness 0.22946684210526314\n",
      "Accepted new solution with fitness 0.23296315789473684\n",
      "Accepted new solution with fitness 0.22946684210526314\n",
      "Accepted new solution with fitness 0.23540684210526314\n",
      "Accepted new solution with fitness 0.23191052631578946\n",
      "Accepted new solution with fitness 0.23191052631578946\n",
      "Accepted new solution with fitness 0.22999315789473684\n",
      "Accepted new solution with fitness 0.22946684210526314\n",
      "Accepted new solution with fitness 0.23540684210526314\n",
      "Accepted new solution with fitness 0.23191052631578946\n",
      "Accepted new solution with fitness 0.23389052631578947\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.23144684210526312\n",
      "Accepted new solution with fitness 0.24239947368421053\n",
      "Accepted new solution with fitness 0.22346421052631577\n",
      "Accepted new solution with fitness 0.22795052631578944\n",
      "Accepted new solution with fitness 0.23191052631578946\n",
      "Accepted new solution with fitness 0.23191052631578946\n",
      "Accepted new solution with fitness 0.23144684210526312\n",
      "Accepted new solution with fitness 0.23593315789473684\n",
      "Accepted new solution with fitness 0.24041947368421052\n",
      "Accepted new solution with fitness 0.24041947368421052\n",
      "Accepted new solution with fitness 0.23045684210526313\n",
      "Accepted new solution with fitness 0.23045684210526313\n",
      "Accepted new solution with fitness 0.23045684210526313\n",
      "Accepted new solution with fitness 0.23942947368421053\n",
      "Accepted new solution with fitness 0.23447947368421052\n",
      "Accepted new solution with fitness 0.23197315789473683\n",
      "Accepted new solution with fitness 0.23342684210526313\n",
      "Accepted new solution with fitness 0.23692315789473684\n",
      "Accepted new solution with fitness 0.2458957894736842\n",
      "Accepted new solution with fitness 0.23692315789473684\n",
      "Accepted new solution with fitness 0.24635947368421052\n",
      "Accepted new solution with fitness 0.2350057894736842\n",
      "Accepted new solution with fitness 0.23599578947368421\n",
      "Accepted new solution with fitness 0.23599578947368421\n",
      "Accepted new solution with fitness 0.23599578947368421\n",
      "Starting SA Iteration 2\n",
      "GSA is optimizing  \"<lambda>\"\n",
      "[iter 1] G=10.0000\n",
      "[iter 1] kbest=20\n",
      "['At iteration 1 the best fitness is 0.22457947368421052']\n",
      "[iter 2] G=9.3551\n",
      "[iter 2] kbest=20\n",
      "['At iteration 2 the best fitness is 0.2214215789473684']\n",
      "[iter 3] G=8.7517\n",
      "[iter 3] kbest=19\n",
      "['At iteration 3 the best fitness is 0.2214215789473684']\n",
      "['At iteration 4 the best fitness is 0.2214215789473684']\n",
      "['At iteration 5 the best fitness is 0.2214215789473684']\n",
      "['At iteration 6 the best fitness is 0.2214215789473684']\n",
      "['At iteration 7 the best fitness is 0.22102052631578945']\n",
      "['At iteration 8 the best fitness is 0.2204315789473684']\n",
      "['At iteration 9 the best fitness is 0.2204315789473684']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At iteration 10 the best fitness is 0.2204315789473684']\n",
      "['At iteration 11 the best fitness is 0.21752421052631576']\n",
      "['At iteration 12 the best fitness is 0.21752421052631576']\n",
      "['At iteration 13 the best fitness is 0.21752421052631576']\n",
      "['At iteration 14 the best fitness is 0.21752421052631576']\n",
      "['At iteration 15 the best fitness is 0.21752421052631576']\n",
      "['At iteration 16 the best fitness is 0.21752421052631576']\n",
      "['At iteration 17 the best fitness is 0.21752421052631576']\n",
      "['At iteration 18 the best fitness is 0.21752421052631576']\n",
      "['At iteration 19 the best fitness is 0.21752421052631576']\n",
      "['At iteration 20 the best fitness is 0.21752421052631576']\n",
      "['At iteration 21 the best fitness is 0.21752421052631576']\n",
      "['At iteration 22 the best fitness is 0.21653421052631575']\n",
      "['At iteration 23 the best fitness is 0.21653421052631575']\n",
      "['At iteration 24 the best fitness is 0.21653421052631575']\n",
      "['At iteration 25 the best fitness is 0.21653421052631575']\n",
      "['At iteration 26 the best fitness is 0.21653421052631575']\n",
      "['At iteration 27 the best fitness is 0.21653421052631575']\n",
      "['At iteration 28 the best fitness is 0.21653421052631575']\n",
      "['At iteration 29 the best fitness is 0.21653421052631575']\n",
      "['At iteration 30 the best fitness is 0.21607052631578944']\n",
      "['At iteration 31 the best fitness is 0.21607052631578944']\n",
      "['At iteration 32 the best fitness is 0.21607052631578944']\n",
      "['At iteration 33 the best fitness is 0.21607052631578944']\n",
      "['At iteration 34 the best fitness is 0.21607052631578944']\n",
      "['At iteration 35 the best fitness is 0.21607052631578944']\n",
      "['At iteration 36 the best fitness is 0.21607052631578944']\n",
      "['At iteration 37 the best fitness is 0.21607052631578944']\n",
      "['At iteration 38 the best fitness is 0.21607052631578944']\n",
      "['At iteration 39 the best fitness is 0.21607052631578944']\n",
      "['At iteration 40 the best fitness is 0.21607052631578944']\n",
      "['At iteration 41 the best fitness is 0.21607052631578944']\n",
      "['At iteration 42 the best fitness is 0.21554421052631575']\n",
      "['At iteration 43 the best fitness is 0.21554421052631575']\n",
      "['At iteration 44 the best fitness is 0.21554421052631575']\n",
      "['At iteration 45 the best fitness is 0.21554421052631575']\n",
      "['At iteration 46 the best fitness is 0.21554421052631575']\n",
      "['At iteration 47 the best fitness is 0.21554421052631575']\n",
      "['At iteration 48 the best fitness is 0.21554421052631575']\n",
      "['At iteration 49 the best fitness is 0.21554421052631575']\n",
      "['At iteration 50 the best fitness is 0.21554421052631575']\n",
      "['At iteration 51 the best fitness is 0.21554421052631575']\n",
      "['At iteration 52 the best fitness is 0.21554421052631575']\n",
      "['At iteration 53 the best fitness is 0.21554421052631575']\n",
      "['At iteration 54 the best fitness is 0.21402789473684208']\n",
      "['At iteration 55 the best fitness is 0.21402789473684208']\n",
      "['At iteration 56 the best fitness is 0.21402789473684208']\n",
      "['At iteration 57 the best fitness is 0.21402789473684208']\n",
      "['At iteration 58 the best fitness is 0.21402789473684208']\n",
      "['At iteration 59 the best fitness is 0.21402789473684208']\n",
      "['At iteration 60 the best fitness is 0.21402789473684208']\n",
      "['At iteration 61 the best fitness is 0.21402789473684208']\n",
      "['At iteration 62 the best fitness is 0.21402789473684208']\n",
      "['At iteration 63 the best fitness is 0.21402789473684208']\n",
      "['At iteration 64 the best fitness is 0.21402789473684208']\n",
      "['At iteration 65 the best fitness is 0.21402789473684208']\n",
      "['At iteration 66 the best fitness is 0.21402789473684208']\n",
      "['At iteration 67 the best fitness is 0.21402789473684208']\n",
      "['At iteration 68 the best fitness is 0.21402789473684208']\n",
      "['At iteration 69 the best fitness is 0.21402789473684208']\n",
      "['At iteration 70 the best fitness is 0.21402789473684208']\n",
      "['At iteration 71 the best fitness is 0.21402789473684208']\n",
      "['At iteration 72 the best fitness is 0.21402789473684208']\n",
      "['At iteration 73 the best fitness is 0.21402789473684208']\n",
      "[iter 74] G=1.0000\n",
      "[iter 74] kbest=5\n",
      "['At iteration 74 the best fitness is 0.21402789473684208']\n",
      "[iter 75] G=2.0000\n",
      "[iter 75] kbest=5\n",
      "['At iteration 75 the best fitness is 0.21402789473684208']\n",
      "Accepted new solution with fitness 0.21402789473684208\n",
      "Accepted new solution with fitness 0.21851421052631576\n",
      "Accepted new solution with fitness 0.21402789473684208\n",
      "Accepted new solution with fitness 0.22498052631578944\n",
      "Accepted new solution with fitness 0.22847684210526312\n",
      "Accepted new solution with fitness 0.22597052631578946\n",
      "Accepted new solution with fitness 0.23395315789473684\n",
      "Accepted new solution with fitness 0.2458957894736842\n",
      "Accepted new solution with fitness 0.23447947368421052\n",
      "Accepted new solution with fitness 0.2612094736842105\n",
      "Accepted new solution with fitness 0.23751210526315789\n",
      "Accepted new solution with fitness 0.25025684210526317\n",
      "Accepted new solution with fitness 0.25025684210526317\n",
      "Accepted new solution with fitness 0.2507205263157895\n",
      "Accepted new solution with fitness 0.25276315789473686\n",
      "Accepted new solution with fitness 0.23197315789473683\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.2454321052631579\n",
      "Accepted new solution with fitness 0.22853947368421051\n",
      "Accepted new solution with fitness 0.22900315789473683\n",
      "Accepted new solution with fitness 0.25177315789473687\n",
      "Accepted new solution with fitness 0.24827684210526316\n",
      "Accepted new solution with fitness 0.23645947368421052\n",
      "Accepted new solution with fitness 0.22900315789473683\n",
      "Accepted new solution with fitness 0.22451684210526313\n",
      "Accepted new solution with fitness 0.22999315789473684\n",
      "Accepted new solution with fitness 0.22451684210526313\n",
      "Accepted new solution with fitness 0.23355210526315787\n",
      "Accepted new solution with fitness 0.2458957894736842\n",
      "Accepted new solution with fitness 0.23454210526315789\n",
      "Accepted new solution with fitness 0.23454210526315789\n",
      "Accepted new solution with fitness 0.2295294736842105\n",
      "Accepted new solution with fitness 0.22603315789473682\n",
      "Accepted new solution with fitness 0.22603315789473682\n",
      "Accepted new solution with fitness 0.2424621052631579\n",
      "Accepted new solution with fitness 0.23902842105263156\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.2379757894736842\n",
      "Accepted new solution with fitness 0.23744947368421052\n",
      "Accepted new solution with fitness 0.23744947368421052\n",
      "Accepted new solution with fitness 0.2379757894736842\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.22399052631578945\n",
      "Accepted new solution with fitness 0.22451684210526313\n",
      "Accepted new solution with fitness 0.22603315789473682\n",
      "Accepted new solution with fitness 0.2295294736842105\n",
      "Accepted new solution with fitness 0.2340157894736842\n",
      "Accepted new solution with fitness 0.23447947368421052\n",
      "Accepted new solution with fitness 0.23348947368421052\n",
      "Starting SA Iteration 3\n",
      "GSA is optimizing  \"<lambda>\"\n",
      "[iter 1] G=10.0000\n",
      "[iter 1] kbest=20\n",
      "['At iteration 1 the best fitness is 0.23909105263157893']\n",
      "[iter 2] G=9.3551\n",
      "[iter 2] kbest=20\n",
      "['At iteration 2 the best fitness is 0.22201052631578944']\n",
      "[iter 3] G=8.7517\n",
      "[iter 3] kbest=19\n",
      "['At iteration 3 the best fitness is 0.22201052631578944']\n",
      "['At iteration 4 the best fitness is 0.22201052631578944']\n",
      "['At iteration 5 the best fitness is 0.22201052631578944']\n",
      "['At iteration 6 the best fitness is 0.22201052631578944']\n",
      "['At iteration 7 the best fitness is 0.22201052631578944']\n",
      "['At iteration 8 the best fitness is 0.22201052631578944']\n",
      "['At iteration 9 the best fitness is 0.22201052631578944']\n",
      "['At iteration 10 the best fitness is 0.22201052631578944']\n",
      "['At iteration 11 the best fitness is 0.22201052631578944']\n",
      "['At iteration 12 the best fitness is 0.22201052631578944']\n",
      "['At iteration 13 the best fitness is 0.21950421052631575']\n",
      "['At iteration 14 the best fitness is 0.21752421052631576']\n",
      "['At iteration 15 the best fitness is 0.21752421052631576']\n",
      "['At iteration 16 the best fitness is 0.21752421052631576']\n",
      "['At iteration 17 the best fitness is 0.21752421052631576']\n",
      "['At iteration 18 the best fitness is 0.21752421052631576']\n",
      "['At iteration 19 the best fitness is 0.21752421052631576']\n",
      "['At iteration 20 the best fitness is 0.21752421052631576']\n",
      "['At iteration 21 the best fitness is 0.21752421052631576']\n",
      "['At iteration 22 the best fitness is 0.21752421052631576']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At iteration 23 the best fitness is 0.21752421052631576']\n",
      "['At iteration 24 the best fitness is 0.21752421052631576']\n",
      "['At iteration 25 the best fitness is 0.21752421052631576']\n",
      "['At iteration 26 the best fitness is 0.21752421052631576']\n",
      "['At iteration 27 the best fitness is 0.21752421052631576']\n",
      "['At iteration 28 the best fitness is 0.21752421052631576']\n",
      "['At iteration 29 the best fitness is 0.21752421052631576']\n",
      "['At iteration 30 the best fitness is 0.21752421052631576']\n",
      "['At iteration 31 the best fitness is 0.21752421052631576']\n",
      "['At iteration 32 the best fitness is 0.21752421052631576']\n",
      "['At iteration 33 the best fitness is 0.21752421052631576']\n",
      "['At iteration 34 the best fitness is 0.21752421052631576']\n",
      "['At iteration 35 the best fitness is 0.21752421052631576']\n",
      "['At iteration 36 the best fitness is 0.21752421052631576']\n",
      "['At iteration 37 the best fitness is 0.21752421052631576']\n",
      "['At iteration 38 the best fitness is 0.21752421052631576']\n",
      "['At iteration 39 the best fitness is 0.21752421052631576']\n",
      "['At iteration 40 the best fitness is 0.21554421052631575']\n",
      "['At iteration 41 the best fitness is 0.21554421052631575']\n",
      "['At iteration 42 the best fitness is 0.21554421052631575']\n",
      "['At iteration 43 the best fitness is 0.21554421052631575']\n",
      "['At iteration 44 the best fitness is 0.21548157894736839']\n",
      "['At iteration 45 the best fitness is 0.21548157894736839']\n",
      "['At iteration 46 the best fitness is 0.21548157894736839']\n",
      "['At iteration 47 the best fitness is 0.21548157894736839']\n",
      "['At iteration 48 the best fitness is 0.21548157894736839']\n",
      "['At iteration 49 the best fitness is 0.21548157894736839']\n",
      "['At iteration 50 the best fitness is 0.21548157894736839']\n",
      "['At iteration 51 the best fitness is 0.21548157894736839']\n",
      "['At iteration 52 the best fitness is 0.21548157894736839']\n",
      "['At iteration 53 the best fitness is 0.21548157894736839']\n",
      "['At iteration 54 the best fitness is 0.21548157894736839']\n",
      "['At iteration 55 the best fitness is 0.21548157894736839']\n",
      "['At iteration 56 the best fitness is 0.21548157894736839']\n",
      "['At iteration 57 the best fitness is 0.21548157894736839']\n",
      "['At iteration 58 the best fitness is 0.21548157894736839']\n",
      "['At iteration 59 the best fitness is 0.21548157894736839']\n",
      "['At iteration 60 the best fitness is 0.21548157894736839']\n",
      "['At iteration 61 the best fitness is 0.21548157894736839']\n",
      "['At iteration 62 the best fitness is 0.21548157894736839']\n",
      "['At iteration 63 the best fitness is 0.21548157894736839']\n",
      "['At iteration 64 the best fitness is 0.21548157894736839']\n",
      "['At iteration 65 the best fitness is 0.21548157894736839']\n",
      "['At iteration 66 the best fitness is 0.21548157894736839']\n",
      "['At iteration 67 the best fitness is 0.21548157894736839']\n",
      "['At iteration 68 the best fitness is 0.21548157894736839']\n",
      "['At iteration 69 the best fitness is 0.21548157894736839']\n",
      "['At iteration 70 the best fitness is 0.21548157894736839']\n",
      "['At iteration 71 the best fitness is 0.21548157894736839']\n",
      "['At iteration 72 the best fitness is 0.21548157894736839']\n",
      "['At iteration 73 the best fitness is 0.21548157894736839']\n",
      "[iter 74] G=1.0000\n",
      "[iter 74] kbest=5\n",
      "['At iteration 74 the best fitness is 0.21548157894736839']\n",
      "[iter 75] G=1.0000\n",
      "[iter 75] kbest=5\n",
      "['At iteration 75 the best fitness is 0.21548157894736839']\n",
      "Accepted new solution with fitness 0.2219478947368421\n",
      "Accepted new solution with fitness 0.21548157894736839\n",
      "Accepted new solution with fitness 0.21548157894736839\n",
      "Accepted new solution with fitness 0.21548157894736839\n",
      "Accepted new solution with fitness 0.21548157894736839\n",
      "Accepted new solution with fitness 0.21851421052631576\n",
      "Accepted new solution with fitness 0.22498052631578944\n",
      "Accepted new solution with fitness 0.22003052631578943\n",
      "Accepted new solution with fitness 0.22696052631578945\n",
      "Accepted new solution with fitness 0.22643421052631577\n",
      "Accepted new solution with fitness 0.2308578947368421\n",
      "Accepted new solution with fitness 0.2308578947368421\n",
      "Accepted new solution with fitness 0.22841421052631578\n",
      "Accepted new solution with fitness 0.22399052631578945\n",
      "Accepted new solution with fitness 0.23039421052631576\n",
      "Accepted new solution with fitness 0.23488052631578946\n",
      "Accepted new solution with fitness 0.23243684210526314\n",
      "Accepted new solution with fitness 0.23488052631578946\n",
      "Accepted new solution with fitness 0.2324994736842105\n",
      "Accepted new solution with fitness 0.23593315789473684\n",
      "Accepted new solution with fitness 0.24484315789473685\n",
      "Accepted new solution with fitness 0.23843947368421053\n",
      "Accepted new solution with fitness 0.24134684210526314\n",
      "Accepted new solution with fitness 0.24286315789473684\n",
      "Accepted new solution with fitness 0.24431684210526314\n",
      "Accepted new solution with fitness 0.24431684210526314\n",
      "Accepted new solution with fitness 0.24484315789473685\n",
      "Accepted new solution with fitness 0.24286315789473684\n",
      "Accepted new solution with fitness 0.24530684210526313\n",
      "Accepted new solution with fitness 0.24530684210526313\n",
      "Accepted new solution with fitness 0.23890315789473685\n",
      "Accepted new solution with fitness 0.24682315789473686\n",
      "Accepted new solution with fitness 0.23540684210526314\n",
      "Accepted new solution with fitness 0.23540684210526314\n",
      "Accepted new solution with fitness 0.23587052631578945\n",
      "Accepted new solution with fitness 0.23587052631578945\n",
      "Accepted new solution with fitness 0.23587052631578945\n",
      "Accepted new solution with fitness 0.23098315789473683\n",
      "Accepted new solution with fitness 0.23144684210526312\n",
      "Accepted new solution with fitness 0.23389052631578947\n",
      "Accepted new solution with fitness 0.23342684210526313\n",
      "Accepted new solution with fitness 0.22689789473684208\n",
      "Accepted new solution with fitness 0.22795052631578944\n",
      "Accepted new solution with fitness 0.22649684210526314\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.24239947368421053\n",
      "Accepted new solution with fitness 0.24088315789473685\n",
      "Accepted new solution with fitness 0.2429257894736842\n",
      "Accepted new solution with fitness 0.22801315789473683\n",
      "Starting SA Iteration 4\n",
      "GSA is optimizing  \"<lambda>\"\n",
      "[iter 1] G=10.0000\n",
      "[iter 1] kbest=20\n",
      "['At iteration 1 the best fitness is 0.2369857894736842']\n",
      "[iter 2] G=9.3551\n",
      "[iter 2] kbest=20\n",
      "['At iteration 2 the best fitness is 0.2324994736842105']\n",
      "[iter 3] G=8.7517\n",
      "[iter 3] kbest=19\n",
      "['At iteration 3 the best fitness is 0.22708578947368419']\n",
      "['At iteration 4 the best fitness is 0.22708578947368419']\n",
      "['At iteration 5 the best fitness is 0.22154684210526313']\n",
      "['At iteration 6 the best fitness is 0.22154684210526313']\n",
      "['At iteration 7 the best fitness is 0.22154684210526313']\n",
      "['At iteration 8 the best fitness is 0.22154684210526313']\n",
      "['At iteration 9 the best fitness is 0.22154684210526313']\n",
      "['At iteration 10 the best fitness is 0.22148421052631576']\n",
      "['At iteration 11 the best fitness is 0.21996789473684208']\n",
      "['At iteration 12 the best fitness is 0.21996789473684208']\n",
      "['At iteration 13 the best fitness is 0.21910315789473683']\n",
      "['At iteration 14 the best fitness is 0.21904052631578944']\n",
      "['At iteration 15 the best fitness is 0.21706052631578943']\n",
      "['At iteration 16 the best fitness is 0.21455421052631576']\n",
      "['At iteration 17 the best fitness is 0.21455421052631576']\n",
      "['At iteration 18 the best fitness is 0.21455421052631576']\n",
      "['At iteration 19 the best fitness is 0.21455421052631576']\n",
      "['At iteration 20 the best fitness is 0.21455421052631576']\n",
      "['At iteration 21 the best fitness is 0.21455421052631576']\n",
      "['At iteration 22 the best fitness is 0.21455421052631576']\n",
      "['At iteration 23 the best fitness is 0.21455421052631576']\n",
      "['At iteration 24 the best fitness is 0.21455421052631576']\n",
      "['At iteration 25 the best fitness is 0.21455421052631576']\n",
      "['At iteration 26 the best fitness is 0.21455421052631576']\n",
      "['At iteration 27 the best fitness is 0.21455421052631576']\n",
      "['At iteration 28 the best fitness is 0.21455421052631576']\n",
      "['At iteration 29 the best fitness is 0.21455421052631576']\n",
      "['At iteration 30 the best fitness is 0.21455421052631576']\n",
      "['At iteration 31 the best fitness is 0.21455421052631576']\n",
      "['At iteration 32 the best fitness is 0.21455421052631576']\n",
      "['At iteration 33 the best fitness is 0.21455421052631576']\n",
      "['At iteration 34 the best fitness is 0.21455421052631576']\n",
      "['At iteration 35 the best fitness is 0.21455421052631576']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At iteration 36 the best fitness is 0.21455421052631576']\n",
      "['At iteration 37 the best fitness is 0.21455421052631576']\n",
      "['At iteration 38 the best fitness is 0.21455421052631576']\n",
      "['At iteration 39 the best fitness is 0.21455421052631576']\n",
      "['At iteration 40 the best fitness is 0.21455421052631576']\n",
      "['At iteration 41 the best fitness is 0.21455421052631576']\n",
      "['At iteration 42 the best fitness is 0.21455421052631576']\n",
      "['At iteration 43 the best fitness is 0.21455421052631576']\n",
      "['At iteration 44 the best fitness is 0.21455421052631576']\n",
      "['At iteration 45 the best fitness is 0.21455421052631576']\n",
      "['At iteration 46 the best fitness is 0.21455421052631576']\n",
      "['At iteration 47 the best fitness is 0.21455421052631576']\n",
      "['At iteration 48 the best fitness is 0.21455421052631576']\n",
      "['At iteration 49 the best fitness is 0.21455421052631576']\n",
      "['At iteration 50 the best fitness is 0.21455421052631576']\n",
      "['At iteration 51 the best fitness is 0.21455421052631576']\n",
      "['At iteration 52 the best fitness is 0.21455421052631576']\n",
      "['At iteration 53 the best fitness is 0.21455421052631576']\n",
      "['At iteration 54 the best fitness is 0.21455421052631576']\n",
      "['At iteration 55 the best fitness is 0.21455421052631576']\n",
      "['At iteration 56 the best fitness is 0.21455421052631576']\n",
      "['At iteration 57 the best fitness is 0.21402789473684208']\n",
      "['At iteration 58 the best fitness is 0.21402789473684208']\n",
      "['At iteration 59 the best fitness is 0.21402789473684208']\n",
      "['At iteration 60 the best fitness is 0.21402789473684208']\n",
      "['At iteration 61 the best fitness is 0.21402789473684208']\n",
      "['At iteration 62 the best fitness is 0.21402789473684208']\n",
      "['At iteration 63 the best fitness is 0.21402789473684208']\n",
      "['At iteration 64 the best fitness is 0.21402789473684208']\n",
      "['At iteration 65 the best fitness is 0.21402789473684208']\n",
      "['At iteration 66 the best fitness is 0.21402789473684208']\n",
      "['At iteration 67 the best fitness is 0.21402789473684208']\n",
      "['At iteration 68 the best fitness is 0.21402789473684208']\n",
      "['At iteration 69 the best fitness is 0.21402789473684208']\n",
      "['At iteration 70 the best fitness is 0.21402789473684208']\n",
      "['At iteration 71 the best fitness is 0.21402789473684208']\n",
      "['At iteration 72 the best fitness is 0.21402789473684208']\n",
      "['At iteration 73 the best fitness is 0.21402789473684208']\n",
      "[iter 74] G=2.0000\n",
      "[iter 74] kbest=5\n",
      "['At iteration 74 the best fitness is 0.21402789473684208']\n",
      "[iter 75] G=1.0000\n",
      "[iter 75] kbest=5\n",
      "['At iteration 75 the best fitness is 0.21402789473684208']\n",
      "Accepted new solution with fitness 0.21805052631578944\n",
      "Accepted new solution with fitness 0.21805052631578944\n",
      "Accepted new solution with fitness 0.21554421052631575\n",
      "Accepted new solution with fitness 0.22841421052631578\n",
      "Accepted new solution with fitness 0.23144684210526312\n",
      "Accepted new solution with fitness 0.22445421052631576\n",
      "Accepted new solution with fitness 0.23098315789473683\n",
      "Accepted new solution with fitness 0.22300052631578945\n",
      "Accepted new solution with fitness 0.23197315789473683\n",
      "Accepted new solution with fitness 0.23395315789473684\n",
      "Accepted new solution with fitness 0.24239947368421053\n",
      "Accepted new solution with fitness 0.22999315789473684\n",
      "Accepted new solution with fitness 0.2518984210526316\n",
      "Accepted new solution with fitness 0.2468857894736842\n",
      "Accepted new solution with fitness 0.2484021052631579\n",
      "Accepted new solution with fitness 0.2484021052631579\n",
      "Accepted new solution with fitness 0.2484021052631579\n",
      "Accepted new solution with fitness 0.2439157894736842\n",
      "Accepted new solution with fitness 0.2439157894736842\n",
      "Accepted new solution with fitness 0.23348947368421052\n",
      "Accepted new solution with fitness 0.2439157894736842\n",
      "Accepted new solution with fitness 0.2504447368421053\n",
      "Accepted new solution with fitness 0.24892842105263158\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.2429257894736842\n",
      "Accepted new solution with fitness 0.2429257894736842\n",
      "Accepted new solution with fitness 0.24787578947368422\n",
      "Accepted new solution with fitness 0.2507831578947368\n",
      "Accepted new solution with fitness 0.2409457894736842\n",
      "Accepted new solution with fitness 0.2409457894736842\n",
      "Accepted new solution with fitness 0.23942947368421053\n",
      "Accepted new solution with fitness 0.2458957894736842\n",
      "Accepted new solution with fitness 0.24985578947368423\n",
      "Accepted new solution with fitness 0.2523621052631579\n",
      "Accepted new solution with fitness 0.24998105263157894\n",
      "Accepted new solution with fitness 0.24496842105263156\n",
      "Accepted new solution with fitness 0.23599578947368421\n",
      "Accepted new solution with fitness 0.2379757894736842\n",
      "Accepted new solution with fitness 0.2429257894736842\n",
      "Accepted new solution with fitness 0.2429257894736842\n",
      "Accepted new solution with fitness 0.23546947368421053\n",
      "Accepted new solution with fitness 0.23546947368421053\n",
      "Accepted new solution with fitness 0.24444210526315788\n",
      "Accepted new solution with fitness 0.24793842105263156\n",
      "Accepted new solution with fitness 0.24351473684210526\n",
      "Accepted new solution with fitness 0.24397842105263157\n",
      "Accepted new solution with fitness 0.24397842105263157\n",
      "Accepted new solution with fitness 0.24397842105263157\n",
      "Accepted new solution with fitness 0.24397842105263157\n",
      "Accepted new solution with fitness 0.2458957894736842\n",
      "Starting SA Iteration 5\n",
      "GSA is optimizing  \"<lambda>\"\n",
      "[iter 1] G=10.0000\n",
      "[iter 1] kbest=20\n",
      "['At iteration 1 the best fitness is 0.24153473684210525']\n",
      "[iter 2] G=9.3551\n",
      "[iter 2] kbest=20\n",
      "['At iteration 2 the best fitness is 0.2365221052631579']\n",
      "[iter 3] G=8.7517\n",
      "[iter 3] kbest=19\n",
      "['At iteration 3 the best fitness is 0.2365221052631579']\n",
      "['At iteration 4 the best fitness is 0.225318947368421']\n",
      "['At iteration 5 the best fitness is 0.225318947368421']\n",
      "['At iteration 6 the best fitness is 0.22399052631578945']\n",
      "['At iteration 7 the best fitness is 0.22102052631578945']\n",
      "['At iteration 8 the best fitness is 0.22102052631578945']\n",
      "['At iteration 9 the best fitness is 0.22102052631578945']\n",
      "['At iteration 10 the best fitness is 0.22102052631578945']\n",
      "['At iteration 11 the best fitness is 0.21950421052631575']\n",
      "['At iteration 12 the best fitness is 0.21950421052631575']\n",
      "['At iteration 13 the best fitness is 0.21897789473684207']\n",
      "['At iteration 14 the best fitness is 0.21897789473684207']\n",
      "['At iteration 15 the best fitness is 0.21897789473684207']\n",
      "['At iteration 16 the best fitness is 0.21897789473684207']\n",
      "['At iteration 17 the best fitness is 0.21554421052631575']\n",
      "['At iteration 18 the best fitness is 0.21554421052631575']\n",
      "['At iteration 19 the best fitness is 0.21554421052631575']\n",
      "['At iteration 20 the best fitness is 0.21554421052631575']\n",
      "['At iteration 21 the best fitness is 0.21554421052631575']\n",
      "['At iteration 22 the best fitness is 0.21554421052631575']\n",
      "['At iteration 23 the best fitness is 0.21402789473684208']\n",
      "['At iteration 24 the best fitness is 0.21402789473684208']\n",
      "['At iteration 25 the best fitness is 0.21402789473684208']\n",
      "['At iteration 26 the best fitness is 0.21402789473684208']\n",
      "['At iteration 27 the best fitness is 0.21402789473684208']\n",
      "['At iteration 28 the best fitness is 0.21402789473684208']\n",
      "['At iteration 29 the best fitness is 0.21402789473684208']\n",
      "['At iteration 30 the best fitness is 0.21402789473684208']\n",
      "['At iteration 31 the best fitness is 0.21402789473684208']\n",
      "['At iteration 32 the best fitness is 0.21402789473684208']\n",
      "['At iteration 33 the best fitness is 0.21402789473684208']\n",
      "['At iteration 34 the best fitness is 0.21402789473684208']\n",
      "['At iteration 35 the best fitness is 0.21402789473684208']\n",
      "['At iteration 36 the best fitness is 0.21402789473684208']\n",
      "['At iteration 37 the best fitness is 0.21402789473684208']\n",
      "['At iteration 38 the best fitness is 0.21402789473684208']\n",
      "['At iteration 39 the best fitness is 0.21402789473684208']\n",
      "['At iteration 40 the best fitness is 0.21402789473684208']\n",
      "['At iteration 41 the best fitness is 0.21402789473684208']\n",
      "['At iteration 42 the best fitness is 0.21402789473684208']\n",
      "['At iteration 43 the best fitness is 0.21402789473684208']\n",
      "['At iteration 44 the best fitness is 0.21402789473684208']\n",
      "['At iteration 45 the best fitness is 0.21402789473684208']\n",
      "['At iteration 46 the best fitness is 0.21402789473684208']\n",
      "['At iteration 47 the best fitness is 0.21402789473684208']\n",
      "['At iteration 48 the best fitness is 0.21402789473684208']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At iteration 49 the best fitness is 0.21402789473684208']\n",
      "['At iteration 50 the best fitness is 0.21402789473684208']\n",
      "['At iteration 51 the best fitness is 0.21402789473684208']\n",
      "['At iteration 52 the best fitness is 0.21402789473684208']\n",
      "['At iteration 53 the best fitness is 0.21402789473684208']\n",
      "['At iteration 54 the best fitness is 0.21402789473684208']\n",
      "['At iteration 55 the best fitness is 0.21402789473684208']\n",
      "['At iteration 56 the best fitness is 0.21402789473684208']\n",
      "['At iteration 57 the best fitness is 0.21402789473684208']\n",
      "['At iteration 58 the best fitness is 0.21402789473684208']\n",
      "['At iteration 59 the best fitness is 0.21402789473684208']\n",
      "['At iteration 60 the best fitness is 0.21402789473684208']\n",
      "['At iteration 61 the best fitness is 0.21402789473684208']\n",
      "['At iteration 62 the best fitness is 0.21402789473684208']\n",
      "['At iteration 63 the best fitness is 0.21402789473684208']\n",
      "['At iteration 64 the best fitness is 0.21402789473684208']\n",
      "['At iteration 65 the best fitness is 0.21402789473684208']\n",
      "['At iteration 66 the best fitness is 0.21402789473684208']\n",
      "['At iteration 67 the best fitness is 0.21402789473684208']\n",
      "['At iteration 68 the best fitness is 0.21402789473684208']\n",
      "['At iteration 69 the best fitness is 0.21402789473684208']\n",
      "['At iteration 70 the best fitness is 0.21402789473684208']\n",
      "['At iteration 71 the best fitness is 0.21402789473684208']\n",
      "['At iteration 72 the best fitness is 0.21402789473684208']\n",
      "['At iteration 73 the best fitness is 0.21402789473684208']\n",
      "[iter 74] G=1.0000\n",
      "[iter 74] kbest=5\n",
      "['At iteration 74 the best fitness is 0.21402789473684208']\n",
      "[iter 75] G=1.0000\n",
      "[iter 75] kbest=5\n",
      "['At iteration 75 the best fitness is 0.21402789473684208']\n",
      "Accepted new solution with fitness 0.21402789473684208\n",
      "Accepted new solution with fitness 0.2214215789473684\n",
      "Accepted new solution with fitness 0.23138421052631578\n",
      "Accepted new solution with fitness 0.22887789473684209\n",
      "Accepted new solution with fitness 0.22102052631578945\n",
      "Accepted new solution with fitness 0.22102052631578945\n",
      "Accepted new solution with fitness 0.22102052631578945\n",
      "Accepted new solution with fitness 0.22102052631578945\n",
      "Accepted new solution with fitness 0.2205568421052631\n",
      "Accepted new solution with fitness 0.2205568421052631\n",
      "Accepted new solution with fitness 0.22154684210526313\n",
      "Accepted new solution with fitness 0.23744947368421052\n",
      "Accepted new solution with fitness 0.23348947368421052\n",
      "Accepted new solution with fitness 0.23896578947368421\n",
      "Accepted new solution with fitness 0.23896578947368421\n",
      "Accepted new solution with fitness 0.23744947368421052\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.23639684210526313\n",
      "Accepted new solution with fitness 0.22049421052631576\n",
      "Accepted new solution with fitness 0.24437947368421054\n",
      "Accepted new solution with fitness 0.24286315789473684\n",
      "Accepted new solution with fitness 0.23738684210526315\n",
      "Accepted new solution with fitness 0.24787578947368422\n",
      "Accepted new solution with fitness 0.24787578947368422\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24147210526315788\n",
      "Accepted new solution with fitness 0.2434521052631579\n",
      "Accepted new solution with fitness 0.24338947368421052\n",
      "Accepted new solution with fitness 0.24041947368421052\n",
      "Accepted new solution with fitness 0.24536947368421053\n",
      "Accepted new solution with fitness 0.2488657894736842\n",
      "Accepted new solution with fitness 0.2464221052631579\n",
      "Accepted new solution with fitness 0.2509084210526316\n",
      "Accepted new solution with fitness 0.2509084210526316\n",
      "Accepted new solution with fitness 0.24694842105263157\n",
      "Accepted new solution with fitness 0.24694842105263157\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.25050736842105265\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24747473684210525\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.24595842105263158\n",
      "Accepted new solution with fitness 0.24991842105263157\n",
      "Accepted new solution with fitness 0.23803842105263157\n",
      "Accepted new solution with fitness 0.24252473684210524\n",
      "Accepted new solution with fitness 0.24846473684210524\n",
      "Accepted new solution with fitness 0.23355210526315787\n",
      "GRAS run total wall-clock: 1979.40s; sum of iteration times: 68.10s\n",
      "Best solution found: [0.         0.01597104 0.11541736 0.         0.06518429 0.\n",
      " 0.51971813 0.53554962 0.3137609  0.01549753 0.         0.04158747\n",
      " 0.07601775 0.00956733 0.66529219 0.         0.         0.36227362\n",
      " 0.4099836 ] with fitness: 0.21402789473684208\n",
      "Saved per-SA-Iteration (per-run) summary: GRAS_summary_KNN_by_SAIteration_20250819_231402.csv\n",
      "\n",
      "Mean ± SD across runs:\n",
      "       Search Time (s)  Eval Time (s)  Wall Clock (s)  Accuracy  Precision  \\\n",
      "mean          13.6202          4.965         18.5858    0.7674     0.5720   \n",
      "std            0.8875          0.000          0.8876    0.0032     0.0074   \n",
      "\n",
      "      Recall  F1 Score     AUC  Selected F (avg)  \n",
      "mean  0.4925    0.5288  0.7752           10.3040  \n",
      "std   0.0067    0.0055  0.0058            1.4699  \n",
      "Results saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hendr\\AppData\\Local\\Temp\\ipykernel_1373324\\3390823431.py:136: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for keys, g in grouped:\n"
     ]
    }
   ],
   "source": [
    "#mencoba algoritma baru2 (10-11-2024)\n",
    "#pakai yang ini\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from utils import get_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import perf_counter\n",
    "\n",
    "#Define parameters for GSA and SA\n",
    "lb = [0] * X_train.shape[1]\n",
    "ub = [1] * X_train.shape[1]\n",
    "dim = len(lb)\n",
    "PopSize = 25  # Number of particles in GSA\n",
    "gsa_iters = 75  # Number of GSA iterations per SA step\n",
    "sa_iters =  10 #50  # Total number of SA steps\n",
    "max_iters = 50  # Max iterations within each SA refinement\n",
    "sa_alpha = 0.93  # Cooling schedule parameter for SA\n",
    "convergence_threshold = 0.001  # Threshold for SA early stopping\n",
    "thr = 0.15\n",
    "num_runs = 1 # Number of independent runs per classifier for robustness\n",
    "\n",
    "\n",
    "# Define the classifiers dictionary\n",
    "# classifiers = {\n",
    "#     \"KNN\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "#     \"SVM\": SVC(probability=True),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "# }\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "#     \"SVM\": SVC(probability=True),\n",
    "#    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "all_results = pd.DataFrame()\n",
    "#avg_and_best_results = pd.DataFrame()\n",
    "\n",
    "# Loop through classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    #classifier_results = []\n",
    "    summary_rows = [] # will store one row per SA Iteration (treated as a \"run\")\n",
    "    \n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Running Adaptive GSA-SA with {name} (Run {run})...\")\n",
    "        t0 = perf_counter()\n",
    "        # Run Adaptive GSA-SA for feature selection\n",
    "        best_solution, results, run_elapsed = gsa_sa_iterative(\n",
    "            X_train, y_train, max_iters=max_iters,\n",
    "            gsa_iters=gsa_iters, sa_iters=sa_iters,\n",
    "            sa_alpha=sa_alpha, \n",
    "            convergence_threshold=convergence_threshold,\n",
    "            clf_name=name\n",
    "        )\n",
    "        \n",
    "        t1 = perf_counter()\n",
    "        \n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "       \n",
    "        # Add evaluation metrics for each subset of features (using 3-fold CV)\n",
    "        kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scoring = {\n",
    "            \"accuracy\":  \"accuracy\",\n",
    "            \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "            \"recall\":    make_scorer(recall_score,    zero_division=0),\n",
    "            \"f1\":        make_scorer(f1_score,        zero_division=0),\n",
    "            \"roc_auc\":   \"roc_auc\",\n",
    "        }\n",
    "\n",
    "\n",
    "        for idx, row in results_df.iterrows():\n",
    "            subset_features = row[\"Feature Set\"]              # list of column indices\n",
    "            Xs = X_train.iloc[:, subset_features].values      # use numpy array for speed\n",
    "            ys = y_train.values.ravel()\n",
    "\n",
    "            # IMPORTANT: clone a fresh classifier each time if you mutate clf elsewhere\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"clf\", clf)])\n",
    "            cvres = cross_validate(pipe, Xs, ys, cv=kf, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "            results_df.loc[idx, \"Accuracy\"]  = cvres[\"test_accuracy\"].mean()\n",
    "            results_df.loc[idx, \"Precision\"] = cvres[\"test_precision\"].mean()\n",
    "            results_df.loc[idx, \"Recall\"]    = cvres[\"test_recall\"].mean()\n",
    "            results_df.loc[idx, \"F1 Score\"]  = cvres[\"test_f1\"].mean()\n",
    "            results_df.loc[idx, \"AUC Score\"] = cvres[\"test_roc_auc\"].mean()\n",
    "\n",
    "        t2 = perf_counter()\n",
    "        \n",
    "        search_time = run_elapsed              # what gsa_sa_iterative measured\n",
    "        eval_time   = t2 - t1                     # CV after the search\n",
    "        wall_time   = t2 - t0                     # total end-to-end\n",
    "\n",
    "        # Use *wall_time* in your summary (or store all three)\n",
    "        results_df[\"Search Time (s)\"] = search_time\n",
    "        results_df[\"Eval Time (s)\"]   = eval_time\n",
    "        results_df[\"Wall Clock (s)\"]  = wall_time\n",
    "        \n",
    "\n",
    "        # Add columns for classifier and run\n",
    "        results_df[\"Classifier\"] = name\n",
    "        results_df[\"Run\"] = run\n",
    "\n",
    "        # Append results to main DataFrame\n",
    "        all_results = pd.concat([all_results, results_df], ignore_index=True)\n",
    "        \n",
    "        # --- Summarize: treat each SA Iteration as ONE \"run\" (aligns with your old SA concept) ---\n",
    "        # If you later set num_runs>1, switch grouping to [\"Run\",\"SA Iteration\"] to keep outer runs separate\n",
    "        group_keys = [\"SA Iteration\"] if num_runs == 1 else [\"Run\", \"SA Iteration\"]\n",
    "        grouped = results_df.groupby(group_keys, as_index=False)\n",
    "        \n",
    "        \n",
    "        def safe_mean(g, col):\n",
    "            return g[col].mean() if (col in g.columns and len(g[col])) else float(\"nan\")\n",
    "        \n",
    "        for keys, g in grouped:\n",
    "            # Unpack keys cleanly\n",
    "            if isinstance(keys, (list, tuple)):\n",
    "                sai = int(keys[-1])\n",
    "                outer = int(keys[0]) if len(keys) == 2 else run\n",
    "            else:\n",
    "                sai = int(keys)\n",
    "                outer = run\n",
    "\n",
    "                \n",
    "            # Per-SA iteration search time: sum of inner iteration times\n",
    "            sa_search_time = float(g[\"Run Time (s)\"].sum()) if \"Run Time (s)\" in g.columns else float(\"nan\")\n",
    "\n",
    "            # If you still want to display eval + wall for each SA iteration,\n",
    "            # you can distribute the one eval block across SA iterations:\n",
    "            sa_eval_time = eval_time / sa_iters\n",
    "            sa_wall_time = sa_search_time + sa_eval_time\n",
    "\n",
    "#             summary_rows.append({\n",
    "#                 \"Classifier\":       name,\n",
    "#                 \"Outer Run\":        outer,                     # only matters if num_runs > 1\n",
    "#                 \"Run\":              sai,                       # SA Iteration => \"Run\" index\n",
    "#                 \"Iterations\":       int(len(g)),               # ~50 inner iterations\n",
    "#                 \"Accuracy\":         safe_mean(g, \"Accuracy\"),\n",
    "#                 \"Precision\":        safe_mean(g, \"Precision\"),\n",
    "#                 \"Recall\":           safe_mean(g, \"Recall\"),\n",
    "#                 \"F1 Score\":         safe_mean(g, \"F1 Score\"),\n",
    "#                 \"AUC\":              safe_mean(g, \"AUC Score\"),\n",
    "#                 \"Selected F (avg)\": safe_mean(g, \"Feature Count\"),\n",
    "#                 # Use sum of per-iteration times if present; else fall back to wall-clock\n",
    "#                 \"Time (seconds)\":   (g[\"Run Time (s)\"].sum() if \"Run Time (s)\" in g.columns else run_elapsed)\n",
    "#             })\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"Classifier\":       name,\n",
    "                \"Outer Run\":        outer,                     # only matters if num_runs > 1\n",
    "                \"Run\":              sai,                       # SA Iteration => \"Run\" index\n",
    "                \"Iterations\":       int(len(g)),               # ~50 inner iterations\n",
    "                \"Accuracy\":         safe_mean(g, \"Accuracy\"),\n",
    "                \"Precision\":        safe_mean(g, \"Precision\"),\n",
    "                \"Recall\":           safe_mean(g, \"Recall\"),\n",
    "                \"F1 Score\":         safe_mean(g, \"F1 Score\"),\n",
    "                \"AUC\":              safe_mean(g, \"AUC Score\"),\n",
    "                \"Selected F (avg)\": safe_mean(g, \"Feature Count\"),\n",
    "                # ✅ Per-SA iteration timing (no more identical values)\n",
    "                \"Search Time (s)\":  round(sa_search_time, 3),\n",
    "                \"Eval Time (s)\":    round(sa_eval_time, 3),\n",
    "                \"Wall Clock (s)\":   round(sa_wall_time, 3),\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ▼▼▼ STEP 3 (cont.): after run loop, write ONE CSV with one row per run ▼▼▼\n",
    "#     summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values([\"Run\"])\n",
    "    timestamp  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     summary_out = f\"GRAS_summary_{name}_{timestamp}.csv\"\n",
    "#     summary_df.to_csv(summary_out, index=False)\n",
    "#     print(\"Saved per-run summary:\", summary_out)\n",
    "    summary_out = f\"GRAS_summary_{name}_by_SAIteration_{timestamp}.csv\"\n",
    "    summary_df.to_csv(summary_out, index=False)\n",
    "    print(\"Saved per-SA-Iteration (per-run) summary:\", summary_out)\n",
    "\n",
    "    # (Optional) quick aggregate for the log\n",
    "#     cols = [\"Time (seconds)\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\", \"Selected F (avg)\"]\n",
    "\n",
    "# (Optional) quick aggregate for the log\n",
    "    cols = [\n",
    "        \"Search Time (s)\", \"Eval Time (s)\", \"Wall Clock (s)\",\n",
    "        \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\", \"Selected F (avg)\"\n",
    "        ]\n",
    "   \n",
    "    print(\"\\nMean ± SD across runs:\\n\", summary_df[cols].agg([\"mean\", \"std\"]).round(4))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Define classifier names\n",
    "classifier_names = \"_\".join(classifiers.keys())  # Combine classifier names into one string    \n",
    "    \n",
    "# Save results to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "all_results.to_csv(f\"adaptive_gsa_sa_results_{classifier_names}_{num_runs}runs_{timestamp}.csv\", index=False)\n",
    "# avg_and_best_results.to_csv(f\"adaptive_gsa_sa_average_best_metrics_{classifier_names}_{num_runs}_{timestamp}.csv\", index=False)\n",
    "\n",
    "print(\"Results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed45788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['churn']),  # Features\n",
    "    df['churn'],                # Target\n",
    "    test_size=0.30,             # 30% for testing\n",
    "    random_state=42             # For reproducibility\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24bee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mencoba algoritma baru (10-11-2024)\n",
    "\n",
    "# Define parameters for GSA and SA\n",
    "lb = [0] * X_train.shape[1]\n",
    "ub = [1] * X_train.shape[1]\n",
    "dim = len(lb)\n",
    "PopSize = 30  # Number of particles in GSA\n",
    "gsa_iters = 20  # Number of GSA iterations per SA step\n",
    "sa_iters =  30 #50  # Total number of SA steps\n",
    "max_iters = 30  # Max iterations within each SA refinement\n",
    "alpha = 0.93  # Cooling schedule parameter for SA\n",
    "convergence_threshold = 0.001  # Threshold for SA early stopping\n",
    "num_runs = 1 # Number of independent runs per classifier for robustness\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb1b83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#mencoba algoritma baru2 (10-11-2024)\n",
    "#pakai yang ini\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from utils import get_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#Define parameters for GSA and SA\n",
    "lb = [0] * X_train.shape[1]\n",
    "ub = [1] * X_train.shape[1]\n",
    "dim = len(lb)\n",
    "PopSize = 20  # Number of particles in GSA\n",
    "gsa_iters = 25  # Number of GSA iterations per SA step\n",
    "sa_iters =  10 #50  # Total number of SA steps\n",
    "max_iters = 50  # Max iterations within each SA refinement\n",
    "alpha = 0.93  # Cooling schedule parameter for SA\n",
    "convergence_threshold = 0.001  # Threshold for SA early stopping\n",
    "num_runs = 1 # Number of independent runs per classifier for robustness\n",
    "\n",
    "\n",
    "# Define the classifiers dictionary\n",
    "# classifiers = {\n",
    "#     \"KNN\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "#     \"SVM\": SVC(probability=True),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "# }\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "#     \"SVM\": SVC(probability=True),\n",
    "#    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Naive Bayes\": GaussianNB(),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "all_results = pd.DataFrame()\n",
    "#avg_and_best_results = pd.DataFrame()\n",
    "\n",
    "# Loop through classifiers\n",
    "for name, clf in classifiers.items():\n",
    "    #classifier_results = []\n",
    "    summary_rows = [] # will store one row per SA Iteration (treated as a \"run\")\n",
    "    \n",
    "    for run in range(1, num_runs + 1):\n",
    "        print(f\"Running Adaptive GSA-SA with {name} (Run {run})...\")\n",
    "\n",
    "        # Run Adaptive GSA-SA for feature selection\n",
    "        best_solution, results, run_elapsed = gsa_sa_iterative(\n",
    "            X_train, y_train, max_iters=max_iters,\n",
    "            gsa_iters=gsa_iters, sa_iters=sa_iters,\n",
    "            alpha=alpha, convergence_threshold=convergence_threshold,\n",
    "            clf_name=name\n",
    "        )\n",
    "\n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "       \n",
    "        # Add evaluation metrics for each subset of features (using 3-fold CV)\n",
    "        kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "        for idx, row in results_df.iterrows():\n",
    "            subset_features = row[\"Feature Set\"]              # list of column indices\n",
    "            Xs = X_train.iloc[:, subset_features].values      # use numpy array for speed\n",
    "            ys = y_train.values.ravel()\n",
    "\n",
    "            # IMPORTANT: clone a fresh classifier each time if you mutate clf elsewhere\n",
    "            model = clf\n",
    "\n",
    "            acc = cross_val_score(model, Xs, ys, cv=kf, scoring=\"accuracy\",  n_jobs=-1).mean()\n",
    "            prec = cross_val_score(model, Xs, ys, cv=kf, scoring=\"precision\", n_jobs=-1).mean()\n",
    "            rec  = cross_val_score(model, Xs, ys, cv=kf, scoring=\"recall\",    n_jobs=-1).mean()\n",
    "            f1   = cross_val_score(model, Xs, ys, cv=kf, scoring=\"f1\",        n_jobs=-1).mean()\n",
    "            auc  = cross_val_score(model, Xs, ys, cv=kf, scoring=\"roc_auc\",   n_jobs=-1).mean()\n",
    "\n",
    "            results_df.loc[idx, \"Accuracy\"]  = acc\n",
    "            results_df.loc[idx, \"Precision\"] = prec\n",
    "            results_df.loc[idx, \"Recall\"]    = rec\n",
    "            results_df.loc[idx, \"F1 Score\"]  = f1\n",
    "            results_df.loc[idx, \"AUC Score\"] = auc\n",
    "\n",
    "\n",
    "        # Add columns for classifier and run\n",
    "        results_df[\"Classifier\"] = name\n",
    "        results_df[\"Run\"] = run\n",
    "\n",
    "        # Append results to main DataFrame\n",
    "        all_results = pd.concat([all_results, results_df], ignore_index=True)\n",
    "        \n",
    "        # --- Summarize: treat each SA Iteration as ONE \"run\" (aligns with your old SA concept) ---\n",
    "        # If you later set num_runs>1, switch grouping to [\"Run\",\"SA Iteration\"] to keep outer runs separate\n",
    "        group_keys = [\"SA Iteration\"] if num_runs == 1 else [\"Run\", \"SA Iteration\"]\n",
    "        grouped = results_df.groupby(group_keys, as_index=False)\n",
    "        \n",
    "        \n",
    "        def safe_mean(g, col):\n",
    "            return g[col].mean() if (col in g.columns and len(g[col])) else float(\"nan\")\n",
    "        \n",
    "        for keys, g in grouped:\n",
    "            # Unpack keys cleanly\n",
    "            if isinstance(keys, (list, tuple)):\n",
    "                sai = int(keys[-1])\n",
    "                outer = int(keys[0]) if len(keys) == 2 else run\n",
    "            else:\n",
    "                sai = int(keys)\n",
    "                outer = run\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"Classifier\":       name,\n",
    "                \"Outer Run\":        outer,                     # only matters if num_runs > 1\n",
    "                \"Run\":              sai,                       # SA Iteration => \"Run\" index\n",
    "                \"Iterations\":       int(len(g)),               # ~50 inner iterations\n",
    "                \"Accuracy\":         safe_mean(g, \"Accuracy\"),\n",
    "                \"Precision\":        safe_mean(g, \"Precision\"),\n",
    "                \"Recall\":           safe_mean(g, \"Recall\"),\n",
    "                \"F1 Score\":         safe_mean(g, \"F1 Score\"),\n",
    "                \"AUC\":              safe_mean(g, \"AUC Score\"),\n",
    "                \"Selected F (avg)\": safe_mean(g, \"Feature Count\"),\n",
    "                # Use sum of per-iteration times if present; else fall back to wall-clock\n",
    "                \"Time (seconds)\":   (g[\"Run Time (s)\"].sum() if \"Run Time (s)\" in g.columns else run_elapsed)\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "    # ▼▼▼ STEP 3 (cont.): after run loop, write ONE CSV with one row per run ▼▼▼\n",
    "#     summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_df = pd.DataFrame(summary_rows).sort_values([\"Run\"])\n",
    "    timestamp  = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "#     summary_out = f\"GRAS_summary_{name}_{timestamp}.csv\"\n",
    "#     summary_df.to_csv(summary_out, index=False)\n",
    "#     print(\"Saved per-run summary:\", summary_out)\n",
    "    summary_out = f\"GRAS_summary_{name}_by_SAIteration_{timestamp}.csv\"\n",
    "    summary_df.to_csv(summary_out, index=False)\n",
    "    print(\"Saved per-SA-Iteration (per-run) summary:\", summary_out)\n",
    "\n",
    "    # (Optional) quick aggregate for the log\n",
    "    cols = [\"Time (seconds)\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"AUC\", \"Selected F (avg)\"]\n",
    "    print(\"\\nMean ± SD across runs:\\n\", summary_df[cols].agg([\"mean\", \"std\"]).round(4))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Define classifier names\n",
    "classifier_names = \"_\".join(classifiers.keys())  # Combine classifier names into one string    \n",
    "    \n",
    "# Save results to CSV\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "all_results.to_csv(f\"adaptive_gsa_sa_results_{classifier_names}_{num_runs}runs_{timestamp}.csv\", index=False)\n",
    "# avg_and_best_results.to_csv(f\"adaptive_gsa_sa_average_best_metrics_{classifier_names}_{num_runs}_{timestamp}.csv\", index=False)\n",
    "\n",
    "print(\"Results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72276981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4606f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the classifiers\n",
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, metric='euclidean'),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# Initialize an empty DataFrame to store average and best metrics for each run\n",
    "avg_and_best_results = pd.DataFrame()\n",
    "\n",
    "# Number of runs\n",
    "num_runs = 10\n",
    "\n",
    "# Define parameters for GSA and SA\n",
    "lb = [0] * X_train.shape[1]\n",
    "ub = [1] * X_train.shape[1]\n",
    "dim = len(lb)\n",
    "PopSize = 30\n",
    "iters = 100\n",
    "\n",
    "# Generate a timestamp for dynamic file names\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Get classifier names for the file name\n",
    "classifier_names = \"_\".join(classifiers.keys())\n",
    "\n",
    "# Loop through each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    classifier_results = []\n",
    "    \n",
    "    for run in range(1, num_runs + 1):\n",
    "        #print(f\"Running FS-SA with {name} (Run {run})...\")\n",
    "        print(f\"Running FS-GSA_SA with {name} (Run {run})...\")\n",
    "        \n",
    "        # Run the simulated annealing process with the current classifier\n",
    "        #results, best_metric, best_subset_cols = simulated_annealing(X_train, y_train, classifier_name=name, run_index=run)\n",
    "        \n",
    "        # Run GSA to get the best solution\n",
    "        gsa_solution = GSA(objf=F1, lb=lb, ub=ub, dim=dim, PopSize=PopSize, iters=iters, df=df)\n",
    "        initial_solution = gsa_solution.gBest\n",
    "\n",
    "        # Run Simulated Annealing with the initial solution from GSA\n",
    "        results, best_metric, best_subset_cols = simulated_annealing(X_train, y_train, classifier_name = name, run_index = run, initial_solution=initial_solution)\n",
    "        \n",
    "        # Add columns for the classifier name and run number\n",
    "        results['Classifier'] = name\n",
    "        results['Run'] = run\n",
    "        \n",
    "        # Append the results to the combined DataFrame\n",
    "        all_results = pd.concat([all_results, results], ignore_index=True)\n",
    "        \n",
    "        # Store the best metric from this run\n",
    "        classifier_results.append(best_metric)\n",
    "        \n",
    "        # Calculate the average metrics for this run\n",
    "        avg_metrics = results.mean()\n",
    "        avg_metrics['Classifier'] = name\n",
    "        avg_metrics['Run'] = run\n",
    "        avg_metrics['Type'] = 'Average'\n",
    "\n",
    "        # Store the best model's metrics\n",
    "        best_metrics = pd.Series(best_metric)\n",
    "        best_metrics['Classifier'] = name\n",
    "        best_metrics['Run'] = run\n",
    "        best_metrics['Type'] = 'Best Model'\n",
    "\n",
    "        # Append to the DataFrame\n",
    "        avg_and_best_results = pd.concat([avg_and_best_results, pd.DataFrame([avg_metrics]), pd.DataFrame([best_metrics])], ignore_index=True)\n",
    "\n",
    "    # Calculate overall averages across all runs for this classifier\n",
    "    overall_avg_metrics = avg_and_best_results[(avg_and_best_results['Classifier'] == name) & (avg_and_best_results['Type'] == 'Average')].mean(numeric_only=True)\n",
    "    overall_avg_metrics['Classifier'] = name\n",
    "    overall_avg_metrics['Run'] = 'Overall Average'\n",
    "    overall_avg_metrics['Type'] = 'Average'\n",
    "\n",
    "    overall_best_metrics = avg_and_best_results[(avg_and_best_results['Classifier'] == name) & (avg_and_best_results['Type'] == 'Best Model')].mean(numeric_only=True)\n",
    "    overall_best_metrics['Classifier'] = name\n",
    "    overall_best_metrics['Run'] = 'Overall Best'\n",
    "    overall_best_metrics['Type'] = 'Best Model'\n",
    "\n",
    "    # Append overall averages to the DataFrame\n",
    "    avg_and_best_results = pd.concat([avg_and_best_results, pd.DataFrame([overall_avg_metrics]), pd.DataFrame([overall_best_metrics])], ignore_index=True)\n",
    "\n",
    "# Dynamic file names\n",
    "output_csv = f'fs_sa_results_{classifier_names}_{num_runs}runs_{timestamp}.csv'\n",
    "average_output_csv = f'fs_sa_average_best_metrics_{classifier_names}_{num_runs}runs_{timestamp}.csv'\n",
    "\n",
    "# Save the combined results to a CSV file\n",
    "all_results.to_csv(output_csv, index=False)\n",
    "\n",
    "# Save the average and best metrics to another CSV file\n",
    "avg_and_best_results.to_csv(average_output_csv, index=False)\n",
    "\n",
    "print(f\"Detailed results saved to {output_csv}\")\n",
    "print(f\"Average and best metrics saved to {average_output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3edd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, best_metric, best_subset_cols = simulated_annealing(X_train, y_train, classifier_name =\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for GSA and SA\n",
    "lb = [0] * X_train.shape[1]\n",
    "ub = [1] * X_train.shape[1]\n",
    "dim = len(lb)\n",
    "PopSize = 30\n",
    "iters = 100\n",
    "\n",
    "# Run GSA to get the best solution\n",
    "gsa_solution = GSA(objf=F1, lb=lb, ub=ub, dim=dim, PopSize=PopSize, iters=iters, df=df)\n",
    "initial_solution = gsa_solution.gBest\n",
    "\n",
    "# Run Simulated Annealing with the initial solution from GSA\n",
    "results, best_metric, best_subset_cols = simulated_annealing(X_train, y_train, initial_solution=initial_solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dee166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e401b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94362f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_subset_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Runs for Robustness Testing\n",
    "num_runs = 10  # Number of runs\n",
    "run_times = []\n",
    "all_metrics = []\n",
    "selected_features_count = []\n",
    "\n",
    "\n",
    "classifier_name = \"KNN\"\n",
    "fitness_function = \"accuracy\"\n",
    "\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Starting Run {run + 1}\")\n",
    "    \n",
    "    # Start the timer for the run\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run the simulated annealing process\n",
    "    results, best_metric, best_subset_cols = simulated_annealing(X_train, y_train, classifier_name, fitness_function, run_index=run+1)\n",
    "    \n",
    "    # End the timer for the run\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate the run time and store it\n",
    "    run_time = end_time - start_time\n",
    "    run_times.append(run_time)\n",
    "    \n",
    "    print(f\"Run {run + 1} completed in {run_time:.2f} seconds\")\n",
    "    \n",
    "    \n",
    "    #store the best metric from this run\n",
    "    all_metrics.append(best_metric)\n",
    "    # Optionally store the results\n",
    "    # all_results.append((results, best_metric, best_subset_cols))\n",
    "    \n",
    "    # Store the number of features selected in this run\n",
    "    selected_features_count.append(len(best_subset_cols))\n",
    "    \n",
    "\n",
    "# After all runs are complete\n",
    "mean_runtime = np.mean(run_times)\n",
    "std_runtime = np.std(run_times)\n",
    "\n",
    "print(f\"Average run time over {num_runs} runs: {mean_runtime:.2f} seconds\")\n",
    "print(f\"Standard deviation of run time: {std_runtime:.2f} seconds\")\n",
    "\n",
    "# Calculate average and standard deviation of each metric\n",
    "avg_metrics = {key: np.mean([metric[key] for metric in all_metrics]) for key in all_metrics[0]}\n",
    "std_metrics = {key: np.std([metric[key] for metric in all_metrics]) for key in all_metrics[0]}\n",
    "\n",
    "# Display average and standard deviation of metrics\n",
    "print(\"\\nAverage Metrics over all runs:\")\n",
    "for metric, value in avg_metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "print(\"\\nStandard Deviation of Metrics over all runs:\")\n",
    "for metric, value in std_metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")\n",
    "\n",
    "# Display the best metrics for each run\n",
    "print(\"\\nBest Metrics from each run:\")\n",
    "for run_index, metrics in enumerate(all_metrics):\n",
    "    print(f\"Run {run_index + 1}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.3f}\")\n",
    "\n",
    "# Calculate and display the average number of features selected\n",
    "average_features_selected = np.mean(selected_features_count)\n",
    "print(f\"\\nAverage number of features selected over {num_runs} runs: {average_features_selected:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863950cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b0fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
